{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28da99-e5ba-4b3d-a365-fe2f395cd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evalscope                # 安装 Native backend (默认)\n",
    "# 额外选项\n",
    "!pip install 'evalscope[opencompass]'   # 安装 OpenCompass backend\n",
    "!pip install 'evalscope[vlmeval]'       # 安装 VLMEvalKit backend\n",
    "!pip install 'evalscope[rag]'           # 安装 RAGEval backend\n",
    "!pip install 'evalscope[perf]'          # 安装 模型压测模块 依赖\n",
    "!pip install 'evalscope[app]'           # 安装 可视化 相关依赖\n",
    "!pip install 'evalscope[all]'           # 安装所有 backends (Native, OpenCompass, VLMEvalKit, RAGEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ccc9e4-f341-44d2-acb3-9531a9d6e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:16:24,598 - evalscope - INFO - Args: Task config is provided with TaskConfig type.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aae40732dbf4e3fafbd24074ca2ae3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:16:34,124 - evalscope - INFO - Dump task config to ./outputs/20250427_191624/configs/task_config_5d1a42.yaml\n",
      "2025-04-27 19:16:34,129 - evalscope - INFO - {\n",
      "    \"model\": \"/root/autodl-tmp/text-generation-webui-2.7/models/Qwen2.5-7B-1M-LT-LB\",\n",
      "    \"model_id\": \"Qwen2.5-7B-1M-LT-LB\",\n",
      "    \"model_args\": {\n",
      "        \"revision\": \"master\",\n",
      "        \"precision\": \"torch.float16\"\n",
      "    },\n",
      "    \"template_type\": null,\n",
      "    \"chat_template\": null,\n",
      "    \"datasets\": [\n",
      "        \"general_mcq\"\n",
      "    ],\n",
      "    \"dataset_args\": {\n",
      "        \"general_mcq\": {\n",
      "            \"name\": \"general_mcq\",\n",
      "            \"dataset_id\": \"/root/LawBench-eval/choose\",\n",
      "            \"model_adapter\": \"multiple_choice_logits\",\n",
      "            \"output_types\": [\n",
      "                \"multiple_choice_logits\",\n",
      "                \"generation\"\n",
      "            ],\n",
      "            \"subset_list\": [\n",
      "                \"1-2知识问答\",\n",
      "                \"2-8论点挖掘\",\n",
      "                \"3-6案例分析\"\n",
      "            ],\n",
      "            \"metric_list\": [\n",
      "                \"AverageAccuracy\"\n",
      "            ],\n",
      "            \"few_shot_num\": 0,\n",
      "            \"few_shot_random\": false,\n",
      "            \"train_split\": \"dev\",\n",
      "            \"eval_split\": \"val\",\n",
      "            \"prompt_template\": \"请回答问题，并选出其中的正确答案\\n{query}\",\n",
      "            \"system_prompt\": null,\n",
      "            \"query_template\": \"问题：{question}\\n{choices}\\n答案: {answer}\\n\\n\",\n",
      "            \"pretty_name\": \"General MCQ\",\n",
      "            \"filters\": null,\n",
      "            \"extra_params\": {}\n",
      "        }\n",
      "    },\n",
      "    \"dataset_dir\": \"/root/.cache/modelscope/hub/datasets\",\n",
      "    \"dataset_hub\": \"modelscope\",\n",
      "    \"generation_config\": {\n",
      "        \"max_length\": 2048,\n",
      "        \"max_new_tokens\": 512,\n",
      "        \"do_sample\": false,\n",
      "        \"top_k\": 50,\n",
      "        \"top_p\": 1.0,\n",
      "        \"temperature\": 1.0\n",
      "    },\n",
      "    \"eval_type\": \"checkpoint\",\n",
      "    \"eval_backend\": \"Native\",\n",
      "    \"eval_config\": null,\n",
      "    \"stage\": \"all\",\n",
      "    \"limit\": null,\n",
      "    \"eval_batch_size\": 1,\n",
      "    \"mem_cache\": false,\n",
      "    \"use_cache\": null,\n",
      "    \"work_dir\": \"./outputs/20250427_191624\",\n",
      "    \"outputs\": null,\n",
      "    \"debug\": false,\n",
      "    \"dry_run\": false,\n",
      "    \"seed\": 42,\n",
      "    \"api_url\": null,\n",
      "    \"api_key\": \"EMPTY\",\n",
      "    \"timeout\": null,\n",
      "    \"stream\": false,\n",
      "    \"judge_strategy\": \"auto\",\n",
      "    \"judge_worker_num\": 1,\n",
      "    \"judge_model_args\": {}\n",
      "}\n",
      "2025-04-27 19:16:34,130 - evalscope - INFO - **** Start evaluating on dataset /root/LawBench-eval/choose ****\n",
      "2025-04-27 19:16:34,131 - evalscope - INFO - Loading dataset from local disk: /root/LawBench-eval/choose\n",
      "2025-04-27 19:16:34,139 - evalscope - INFO - Use default settings: > few_shot_num: 0, > few_shot_split: dev, > target_eval_split: val\n",
      "Predicting(1-2知识问答): 100%|██████████| 500/500 [00:17<00:00, 27.78it/s]\n",
      "2025-04-27 19:16:52,149 - evalscope - INFO - Dump predictions to ./outputs/20250427_191624/predictions/Qwen2.5-7B-1M-LT-LB/general_mcq_1-2知识问答.jsonl.\n",
      "Reviewing(1-2知识问答): 100%|██████████| 500/500 [00:00<00:00, 18247.53it/s]\n",
      "Predicting(2-8论点挖掘): 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "2025-04-27 19:17:09,261 - evalscope - INFO - Dump predictions to ./outputs/20250427_191624/predictions/Qwen2.5-7B-1M-LT-LB/general_mcq_2-8论点挖掘.jsonl.\n",
      "Reviewing(2-8论点挖掘): 100%|██████████| 500/500 [00:00<00:00, 20501.42it/s]\n",
      "Predicting(3-6案例分析): 100%|██████████| 500/500 [00:21<00:00, 22.98it/s]\n",
      "2025-04-27 19:17:31,079 - evalscope - INFO - Dump predictions to ./outputs/20250427_191624/predictions/Qwen2.5-7B-1M-LT-LB/general_mcq_3-6案例分析.jsonl.\n",
      "Reviewing(3-6案例分析): 100%|██████████| 500/500 [00:00<00:00, 15715.24it/s]\n",
      "2025-04-27 19:17:31,159 - evalscope - INFO - Dump report: ./outputs/20250427_191624/reports/Qwen2.5-7B-1M-LT-LB/general_mcq.json \n",
      "\n",
      "2025-04-27 19:17:31,165 - evalscope - INFO - Report table: \n",
      "+---------------------+-------------+-----------------+-------------+-------+---------+---------+\n",
      "| Model               | Dataset     | Metric          | Subset      |   Num |   Score | Cat.0   |\n",
      "+=====================+=============+=================+=============+=======+=========+=========+\n",
      "| Qwen2.5-7B-1M-LT-LB | general_mcq | AverageAccuracy | 1-2知识问答 |   500 |   0.546 | default |\n",
      "+---------------------+-------------+-----------------+-------------+-------+---------+---------+\n",
      "| Qwen2.5-7B-1M-LT-LB | general_mcq | AverageAccuracy | 2-8论点挖掘 |   500 |   0.214 | default |\n",
      "+---------------------+-------------+-----------------+-------------+-------+---------+---------+\n",
      "| Qwen2.5-7B-1M-LT-LB | general_mcq | AverageAccuracy | 3-6案例分析 |   500 |   0.484 | default |\n",
      "+---------------------+-------------+-----------------+-------------+-------+---------+---------+ \n",
      "\n",
      "2025-04-27 19:17:31,166 - evalscope - INFO - **** Evaluation finished on /root/LawBench-eval/choose ****\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'general_mcq': Report(name='Qwen2.5-7B-1M-LT-LB_general_mcq', dataset_name='general_mcq', model_name='Qwen2.5-7B-1M-LT-LB', score=0.4147, metrics=[Metric(name='AverageAccuracy', num=1500, score=0.4147, macro_score=0.4147, categories=[Category(name=('default',), num=1500, score=0.4147, macro_score=0.4147, subsets=[Subset(name='1-2知识问答', score=0.546, num=500), Subset(name='2-8论点挖掘', score=0.214, num=500), Subset(name='3-6案例分析', score=0.484, num=500)])])])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalscope import TaskConfig, run_task\n",
    "\n",
    "task_cfg = TaskConfig(\n",
    "    model='/root/autodl-tmp/text-generation-webui-2.7/models/Qwen2.5-7B-1M-LT-LB',\n",
    "    datasets=['general_mcq'],  # 数据格式，选择题格式固定为 'general_mcq'\n",
    "    dataset_args={\n",
    "        'general_mcq': {\n",
    "            \"local_path\": \"/root/LawBench-eval/choose\",  # 自定义数据集路径\n",
    "            \"subset_list\": [\n",
    "                \"1-2知识问答\",\n",
    "                \"2-2纠纷焦点识别\",\n",
    "                \"2-3婚姻纠纷鉴定\",\n",
    "                \"2-4问题主题识别\",\n",
    "                \"2-8论点挖掘\",\n",
    "                \"2-9事件检测\",\n",
    "                \"3-6案例分析\"\n",
    "                # 评测数据集名称，上述subset_name\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    ")\n",
    "run_task(task_cfg=task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05aa03e-71b0-4efb-9c5c-3d1bf66a95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:17:31,434 - evalscope - INFO - Args: Task config is provided with TaskConfig type.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a15f95d1f41afac7e8062611f23f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:17:36,810 - evalscope - WARNING - Got local model dir: /root/autodl-tmp/text-generation-webui-2.7/models/Qwen2.5-7B-1M\n",
      "2025-04-27 19:17:36,811 - evalscope - INFO - Updating generation config ...\n",
      "2025-04-27 19:17:36,841 - evalscope - INFO - Dump task config to ./outputs/20250427_191731/configs/task_config_27ca70.yaml\n",
      "2025-04-27 19:17:36,845 - evalscope - INFO - {\n",
      "    \"model\": \"/root/autodl-tmp/text-generation-webui-2.7/models/Qwen2.5-7B-1M\",\n",
      "    \"model_id\": \"Qwen2.5-7B-1M\",\n",
      "    \"model_args\": {\n",
      "        \"revision\": \"master\",\n",
      "        \"precision\": \"torch.float16\"\n",
      "    },\n",
      "    \"template_type\": null,\n",
      "    \"chat_template\": null,\n",
      "    \"datasets\": [\n",
      "        \"general_qa\"\n",
      "    ],\n",
      "    \"dataset_args\": {\n",
      "        \"general_qa\": {\n",
      "            \"name\": \"general_qa\",\n",
      "            \"dataset_id\": \"/root/LawBench-eval/text\",\n",
      "            \"model_adapter\": \"generation\",\n",
      "            \"output_types\": [\n",
      "                \"generation\"\n",
      "            ],\n",
      "            \"subset_list\": [\n",
      "                \"1-1法条背诵\",\n",
      "                \"2-1文件校对\",\n",
      "                \"2-2纠纷焦点识别\",\n",
      "                \"2-3婚姻纠纷鉴定\",\n",
      "                \"2-4问题主题识别\",\n",
      "                \"2-5阅读理解\",\n",
      "                \"2-6命名实体识别\",\n",
      "                \"2-7舆情摘要\",\n",
      "                \"2-9事件检测\",\n",
      "                \"2-10触发词提取\",\n",
      "                \"3-1法条预测(基于事实)\",\n",
      "                \"3-2法条预测(基于场景)\",\n",
      "                \"3-3罪名预测\",\n",
      "                \"3-4刑期预测(无法条内容)\",\n",
      "                \"3-5刑期预测(给定法条内容)\",\n",
      "                \"3-7犯罪金额计算\",\n",
      "                \"3-8咨询\"\n",
      "            ],\n",
      "            \"metric_list\": [\n",
      "                \"AverageBLEU\",\n",
      "                \"AverageRouge\"\n",
      "            ],\n",
      "            \"few_shot_num\": 0,\n",
      "            \"few_shot_random\": false,\n",
      "            \"train_split\": null,\n",
      "            \"eval_split\": \"test\",\n",
      "            \"prompt_template\": \"请回答问题\\n{query}\",\n",
      "            \"system_prompt\": null,\n",
      "            \"query_template\": null,\n",
      "            \"pretty_name\": null,\n",
      "            \"filters\": null,\n",
      "            \"extra_params\": {}\n",
      "        }\n",
      "    },\n",
      "    \"dataset_dir\": \"/root/.cache/modelscope/hub/datasets\",\n",
      "    \"dataset_hub\": \"modelscope\",\n",
      "    \"generation_config\": {\n",
      "        \"max_length\": 2048,\n",
      "        \"max_new_tokens\": 512,\n",
      "        \"do_sample\": false,\n",
      "        \"top_k\": 50,\n",
      "        \"top_p\": 1.0,\n",
      "        \"temperature\": 1.0\n",
      "    },\n",
      "    \"eval_type\": \"checkpoint\",\n",
      "    \"eval_backend\": \"Native\",\n",
      "    \"eval_config\": null,\n",
      "    \"stage\": \"all\",\n",
      "    \"limit\": null,\n",
      "    \"eval_batch_size\": 1,\n",
      "    \"mem_cache\": false,\n",
      "    \"use_cache\": null,\n",
      "    \"work_dir\": \"./outputs/20250427_191731\",\n",
      "    \"outputs\": null,\n",
      "    \"debug\": false,\n",
      "    \"dry_run\": false,\n",
      "    \"seed\": 42,\n",
      "    \"api_url\": null,\n",
      "    \"api_key\": \"EMPTY\",\n",
      "    \"timeout\": null,\n",
      "    \"stream\": false,\n",
      "    \"judge_strategy\": \"auto\",\n",
      "    \"judge_worker_num\": 1,\n",
      "    \"judge_model_args\": {}\n",
      "}\n",
      "2025-04-27 19:17:36,847 - evalscope - INFO - **** Start evaluating on dataset /root/LawBench-eval/text ****\n",
      "2025-04-27 19:17:36,951 - evalscope - INFO - Use default settings: > few_shot_num: 0, > few_shot_split: None, > target_eval_split: test\n",
      "Predicting(1-1法条背诵):   0%|          | 20/8500 [00:21<1:54:56,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "from evalscope import TaskConfig, run_task\n",
    "\n",
    "task_cfg = TaskConfig(\n",
    "    model='/root/autodl-tmp/text-generation-webui-2.7/models/Qwen2.5-7B-1M',\n",
    "    datasets=['general_qa'],  # 数据格式，选择题格式固定为 'general_qa'\n",
    "    dataset_args={\n",
    "        'general_qa': {\n",
    "            \"local_path\": \"/root/LawBench-eval/text\",  # 自定义数据集路径\n",
    "            \"subset_list\": [\n",
    "                \"1-1法条背诵\",\n",
    "                \"2-1文件校对\",\n",
    "                \"2-5阅读理解\",\n",
    "                \"2-6命名实体识别\",\n",
    "                \"2-7舆情摘要\",\n",
    "                \"2-10触发词提取\",\n",
    "                \"3-1法条预测(基于事实)\",\n",
    "                \"3-2法条预测(基于场景)\",\n",
    "                \"3-3罪名预测\",\n",
    "                \"3-4刑期预测(无法条内容)\",\n",
    "                \"3-5刑期预测(给定法条内容)\",\n",
    "                \"3-7犯罪金额计算\",\n",
    "                \"3-8咨询\" # 评测数据集名称，上述 *.jsonl 中的 *\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "run_task(task_cfg=task_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
